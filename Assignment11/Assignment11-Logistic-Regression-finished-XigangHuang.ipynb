{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading dataset\n",
    "churn_train = pd.read_csv('udel-churn-train.csv')\n",
    "churn_test = pd.read_csv('udel-churn-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5634 entries, 0 to 5633\n",
      "Data columns (total 22 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Unnamed: 0        5634 non-null   int64  \n",
      " 1   customerID        5634 non-null   object \n",
      " 2   gender            5589 non-null   object \n",
      " 3   SeniorCitizen     5573 non-null   float64\n",
      " 4   Partner           5594 non-null   object \n",
      " 5   Dependents        5594 non-null   object \n",
      " 6   tenure            5544 non-null   float64\n",
      " 7   PhoneService      5550 non-null   object \n",
      " 8   MultipleLines     5580 non-null   object \n",
      " 9   InternetService   5486 non-null   object \n",
      " 10  OnlineSecurity    5564 non-null   object \n",
      " 11  OnlineBackup      5528 non-null   object \n",
      " 12  DeviceProtection  5564 non-null   object \n",
      " 13  TechSupport       5564 non-null   object \n",
      " 14  StreamingTV       5529 non-null   object \n",
      " 15  StreamingMovies   5578 non-null   object \n",
      " 16  Contract          5555 non-null   object \n",
      " 17  PaperlessBilling  5594 non-null   object \n",
      " 18  PaymentMethod     5541 non-null   object \n",
      " 19  MonthlyCharges    5546 non-null   float64\n",
      " 20  TotalCharges      5558 non-null   float64\n",
      " 21  Churn             5634 non-null   object \n",
      "dtypes: float64(4), int64(1), object(17)\n",
      "memory usage: 968.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# create a deepy copy\n",
    "df_train = churn_train.copy()\n",
    "df_train['TotalCharges']=pd.to_numeric(df_train['TotalCharges'], errors='coerce')\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfee2193dc5c4732b972597d98527ad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='variables', max=22.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a5af996a43a417e80f197fd73b4b1bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='table', max=1.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8922947e9d9d433ca4e204ae6b94a69a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='warnings', max=3.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbcbff4b67fc4278acc0b814d6d3c900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='package', max=1.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0b3d20b5524891ab5b0a5535ef6a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='build report structure', max=1.0, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "343b9754594541a39c2e08e081604d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Tab(children=(GridBox(children=(VBox(children=(GridspecLayout(children=(HTML(value='Number of va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Report generated with <a href=\"https://github.com/pandas-profiling/pandas-profiling\">pandas-profiling</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pandas-profiling packages\n",
    "from pandas_profiling import ProfileReport\n",
    "profile = ProfileReport(df_train,minimal=True)\n",
    "profile.to_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first find the numerical and categorical features\n",
    "df_train_num = df_train.select_dtypes(exclude='object')\n",
    "df_train_cat = df_train.select_dtypes(include='object')\n",
    "num_features = df_train_num.columns.tolist()\n",
    "cat_features = df_train_cat.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the target variable \"Churn\" and the unuseful features \"customerID\",\"Unnamed: 0\"\n",
    "# cat_features.remove('Churn')\n",
    "# cat_features.remove('customerID')\n",
    "cat_features = [e for e in cat_features if e not in ('Churn','customerID')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classified some numerical variables into categorical variables\n",
    "num_to_cat = []\n",
    "\n",
    "df_train['SeniorCitizen'].value_counts()\n",
    "num_to_cat.append('SeniorCitizen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this features to categorical\n",
    "num_features = [element for element in num_features if element not in num_to_cat]\n",
    "cat_features += num_to_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the IQR outlier remover\n",
    "# note that you have to remove the rows for both X and y \n",
    "\n",
    "def find_outlier_iqr(X):\n",
    "    # calculate IQR\n",
    "    q1 = X.quantile(0.25)\n",
    "    q3 = X.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    \n",
    "    outlier_index = ((X < (q1 - 1.5 * iqr)) | (X > (q3 + 1.5 * iqr))).any(axis=1)\n",
    "    \n",
    "    return outlier_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we will remove 0.28% outliers\n"
     ]
    }
   ],
   "source": [
    "# this shows how many outliers will be removed from the dataset\n",
    "outlier_index = find_outlier_iqr(df_train[num_features])\n",
    "# before remove outliers\n",
    "len_df_train = len(df_train)\n",
    "# remove the outliers from the dataset\n",
    "df_train_iqr = df_train[~outlier_index]\n",
    "# after remove outliers\n",
    "len_df_train_after = len(df_train_iqr)\n",
    "print(f'we will remove {(len_df_train-len_df_train_after)/len_df_train:.2%} outliers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "X = df_train_iqr.drop(['Churn'],axis=1)\n",
    "y = df_train_iqr['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'customerID', 'gender', 'SeniorCitizen', 'Partner',\n",
       "       'Dependents', 'tenure', 'PhoneService', 'MultipleLines',\n",
       "       'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
       "       'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract',\n",
       "       'PaperlessBilling', 'PaymentMethod', 'MonthlyCharges', 'TotalCharges',\n",
       "       'Churn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_iqr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4494, 21)\n",
      "(1124, 21)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into a training set and a test set. \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the pipeline\n",
    "# Create the preprocessing pipeline for numerical and categorical features\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "num_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('num_imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ]\n",
    ")\n",
    "\n",
    "cat_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('cat_imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine two pipelines to form the preprocessor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num_pipeline', num_pipeline, num_features),\n",
    "        ('cat_pipeline', cat_pipeline, cat_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a full pipeline by combining preprocessor and the model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "tree_clf_model = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('tree_clf', DecisionTreeClassifier()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "log_reg_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('log_reg', LogisticRegression()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "svm_clf_model = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('svm_clf',SVC()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use grid search to find the best decision tree model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# here you must use the step names as the prefix followed by two under_scores to sepecify the parameter names\n",
    "# you also need to specify the \"full path\" of the steps\n",
    "# as you can see we can even grid search parameters for preprocessing pipeline step\n",
    "param_grid = [\n",
    "    {\n",
    "        'preprocessor__num_pipeline__num_imputer__strategy': ['mean', 'median'],\n",
    "        'tree_clf__criterion': ['gini', 'entropy'], \n",
    "        'tree_clf__max_depth': [2, 3, 4, 5, 6, 7],\n",
    "    }\n",
    "]\n",
    "\n",
    "# set up the grid search \n",
    "grid_search = GridSearchCV(tree_clf_model, param_grid, cv=5,\n",
    "                          scoring='accuracy',\n",
    "                          return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('preprocessor',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='drop',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('num_pipeline',\n",
       "                                                                         Pipeline(memory=None,\n",
       "                                                                                  steps=[('num_imputer',\n",
       "                                                                                          SimpleImputer(add_indicator=False,\n",
       "                                                                                                        copy=True,\n",
       "                                                                                                        fill_value=None,\n",
       "                                                                                                        missing_values=nan,\n",
       "                                                                                                        strategy='mean',\n",
       "                                                                                                        v...\n",
       "                                                               presort='deprecated',\n",
       "                                                               random_state=None,\n",
       "                                                               splitter='best'))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'preprocessor__num_pipeline__num_imputer__strategy': ['mean',\n",
       "                                                                                'median'],\n",
       "                          'tree_clf__criterion': ['gini', 'entropy'],\n",
       "                          'tree_clf__max_depth': [2, 3, 4, 5, 6, 7]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using the full pipeline\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'preprocessor__num_pipeline__num_imputer__strategy': 'median',\n",
       " 'tree_clf__criterion': 'gini',\n",
       " 'tree_clf__max_depth': 5}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the best performing parameter combination\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the best trained model\n",
    "tree_clf_best = grid_search.best_estimator_\n",
    "\n",
    "# prediction for the test set\n",
    "y_pred = tree_clf_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv saved! please submit the prediction csv to Kaggle.com\n"
     ]
    }
   ],
   "source": [
    "# make predictions for kaggle submission\n",
    "churn_test = pd.read_csv('udel-churn-test.csv')\n",
    "\n",
    "y_pred_churn = tree_clf_best.predict(churn_test)\n",
    "\n",
    "# combine id and prediction for kaggle submission\n",
    "churn_submit = pd.DataFrame({\n",
    "    'customerID': churn_test['customerID'],\n",
    "    'Churn': y_pred_churn\n",
    "})\n",
    "\n",
    "# generate the csv\n",
    "churn_submit.to_csv('churn-submit_decisiontree.csv', index=False)\n",
    "print('csv saved! please submit the prediction csv to Kaggle.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation average accuracy score: 0.8032927493194754\n"
     ]
    }
   ],
   "source": [
    "# conduct cross validation with the full pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "log_reg_scores_accu = cross_val_score(log_reg_pipeline, X_train, y_train, scoring=\"accuracy\", cv=10)\n",
    "print(f'cross validation average accuracy score: {log_reg_scores_accu.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.54258585]\n",
      "[[ 3.85548276e-02 -1.24219442e+00  7.96144787e-01  4.39799911e-01\n",
      "  -2.92194291e-02 -1.85655163e-04 -7.67030269e-03 -2.17347816e-02\n",
      "   5.02181446e-02 -7.96232289e-02  5.60660532e-01 -5.90065616e-01\n",
      "  -3.81147407e-04 -1.68925461e-01  1.39901524e-01  9.06018261e-03\n",
      "   8.20767179e-02 -1.20541985e-01  2.49052250e-01 -4.20744116e-02\n",
      "  -2.36382923e-01 -3.41575404e-02  2.87624508e-01 -2.82872052e-01\n",
      "   1.55038853e-02 -4.20744116e-02 -2.83455801e-03  2.79750606e-01\n",
      "  -4.20744116e-02 -2.67081279e-01 -1.49010552e-01  3.14763266e-01\n",
      "  -1.95157799e-01  5.72547863e-02 -1.51958584e-01  6.52987137e-02\n",
      "   7.69188406e-01  4.81560201e-02 -8.46749510e-01 -2.03444624e-01\n",
      "   1.74039540e-01 -1.39952064e-01 -6.94813222e-02  1.92829147e-01\n",
      "  -1.28008449e-02 -8.12650851e-02  5.18600008e-02]]\n",
      "Testing set accuracy score : 0.791814946619217\n"
     ]
    }
   ],
   "source": [
    "# we train the final model using ALL training data\n",
    "log_reg_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# # use named_steps[] to access any step in your pipeline\n",
    "print(log_reg_pipeline.named_steps['log_reg'].intercept_)\n",
    "print(log_reg_pipeline.named_steps['log_reg'].coef_)\n",
    "\n",
    "# get the prediction results from the testing set\n",
    "y_pred = log_reg_pipeline.predict(X_test)\n",
    "\n",
    "# calculate accuracy\n",
    "# we have similiar score for the testing set as the cross validation score - good\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(f'Testing set accuracy score : {accuracy_score(y_test,y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv saved! please submit the prediction csv to Kaggle.com\n"
     ]
    }
   ],
   "source": [
    "# make prediction using linear regression model\n",
    "y_pred_logistic = log_reg_pipeline.predict(churn_test)\n",
    "\n",
    "# combine id and prediction for kaggle submission\n",
    "churn_submit = pd.DataFrame({\n",
    "    'customerID': churn_test['customerID'],\n",
    "    'Churn': y_pred_logistic\n",
    "})\n",
    "\n",
    "# generate the csv\n",
    "churn_submit.to_csv('churn-submit_log.csv', index=False)\n",
    "print('csv saved! please submit the prediction csv to Kaggle.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use grid search to find the best decision tree model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# here you must use the step names as the prefix followed by two under_scores to sepecify the parameter names\n",
    "# you also need to specify the \"full path\" of the steps\n",
    "# as you can see we can even grid search parameters for preprocessing pipeline step\n",
    "param_grid = [\n",
    "    {\n",
    "        'svm_clf__kernel': ['linear','poly','rbf'],\n",
    "        'svm_clf__degree': [1,2,3], \n",
    "        'svm_clf__C': [1,3,5],\n",
    "    }\n",
    "]\n",
    "\n",
    "# set up the grid search \n",
    "grid_search = GridSearchCV(svm_clf_model, param_grid, cv=5,\n",
    "                          scoring='accuracy',\n",
    "                          return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('preprocessor',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='drop',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('num_pipeline',\n",
       "                                                                         Pipeline(memory=None,\n",
       "                                                                                  steps=[('num_imputer',\n",
       "                                                                                          SimpleImputer(add_indicator=False,\n",
       "                                                                                                        copy=True,\n",
       "                                                                                                        fill_value=None,\n",
       "                                                                                                        missing_values=nan,\n",
       "                                                                                                        strategy='mean',\n",
       "                                                                                                        v...\n",
       "                                            degree=3, gamma='scale',\n",
       "                                            kernel='rbf', max_iter=-1,\n",
       "                                            probability=False,\n",
       "                                            random_state=None, shrinking=True,\n",
       "                                            tol=0.001, verbose=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'svm_clf__C': [1, 3, 5], 'svm_clf__degree': [1, 2, 3],\n",
       "                          'svm_clf__kernel': ['linear', 'poly', 'rbf']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svm_clf__C': 1, 'svm_clf__degree': 2, 'svm_clf__kernel': 'poly'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessor',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('num_pipeline',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('num_imputer',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=None,\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 strategy='mean',\n",
       "                                                                                 verbose=0)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler(copy=Tru...\n",
       "                                                   'TechSupport', 'StreamingTV',\n",
       "                                                   'StreamingMovies',\n",
       "                                                   'Contract',\n",
       "                                                   'PaperlessBilling',\n",
       "                                                   'PaymentMethod',\n",
       "                                                   'SeniorCitizen'])],\n",
       "                                   verbose=False)),\n",
       "                ('svm_clf',\n",
       "                 SVC(C=1, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovr', degree=2,\n",
       "                     gamma='scale', kernel='poly', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_reg_best = grid_search.best_estimator_\n",
    "SVM_reg_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv saved! please submit the prediction csv to Kaggle.com\n"
     ]
    }
   ],
   "source": [
    "# make predictions for kaggle submission\n",
    "y_pred_churn = SVM_reg_best.predict(churn_test)\n",
    "\n",
    "# combine id and prediction for kaggle submission\n",
    "churn_submit = pd.DataFrame({\n",
    "    'customerID': churn_test['customerID'],\n",
    "    'Churn': y_pred_churn\n",
    "})\n",
    "\n",
    "# generate the csv\n",
    "churn_submit.to_csv('churn-submit_SVM.csv', index=False)\n",
    "print('csv saved! please submit the prediction csv to Kaggle.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
